{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":62857,"databundleVersionId":6886092,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport spacy as sp\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\nfrom collections import Counter\nimport nltk\nnltk.download('stopwords')\n!pip install -q wordcloud\nimport wordcloud\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import learning_curve\n# nltk.download('wordnet')\n# nltk.download('punkt')\n# nltk.download('averaged_perceptron_tagger')\n# nltk.download('omw-1.4')\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt \nfrom IPython.core.display import Path\nfrom mlxtend.plotting import plot_learning_curves\n# !pip install -U spacy\n# !python -m spacy download el_core_news_lg\nimport spacy\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-12T16:48:26.412451Z","iopub.execute_input":"2023-11-12T16:48:26.412863Z","iopub.status.idle":"2023-11-12T16:48:40.882104Z","shell.execute_reply.started":"2023-11-12T16:48:26.412831Z","shell.execute_reply":"2023-11-12T16:48:40.880752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nowords=[\n#     'αλλα', 'αντι', 'απο', 'αυτα', 'αυτες', 'αυτη', 'αυτο', 'αυτον', 'αυτοι', 'αυτος', 'αυτου', 'αυτων', 'δεν', 'δια', 'εαν', 'εγινε', 'εκανε',\n#          'ετσι', 'ειμαι', 'ειναι', 'ειχε', 'εκει', 'εξης', 'επι', 'επομενως', 'επισης', 'εσεις', 'εσενα', 'εσυ', 'ευχαριστω', 'εως', 'η', 'η', 'ηδη',\n#          'ηταν', 'θα', 'και', 'κατα', 'κατι', 'κατι', 'κι', 'κιολας', 'κοντα', 'κτλ.', 'μα', 'με', 'μεσα', 'μεχρι', 'μη', 'μην', 'μια', 'μου', 'μονο',\n#          'ναι', 'να', 'ναι', 'ναι', 'νομιζα', 'ξανα', 'ο', 'οι', 'ολα', 'ολα', 'οποια', 'οποιο', 'οποιος', 'οποιου', 'οποιων', 'οποιως', 'οτι', 'ουτε'\n#          , 'παλι', 'παντα', 'πανω', 'περι', 'πολλα', 'πολυ', 'που', 'προς', 'προτου', 'πως', 'σαν', 'σε', 'σεις', 'στη', 'στην', 'στης', 'στις', 'στο', \n#          'στον', 'συν', 'τα', 'τη', 'την', 'της', 'τι', 'τιποτα', 'το', 'τον', 'τοσο', 'τοσο', 'του', 'τους', 'τουτο', 'τουτοι', 'τουτος', 'τουτου', 'τουτων',\n#          'τωρα', 'υπερ', 'υπο', 'υποψη', 'χωρις', 'ομως', 'τοτε', 'εκεινο', 'εκεινοι', 'εκεινος', 'εκεινου', 'εκεινων', 'εξαιρεση', 'ειδε', 'ειμαστε', 'ειστε', 'ειχα', 'ειχε', 'εκτος', 'εκτος', 'εξηγησε', 'εξακολουθει', 'εξηγει', 'εξηγησει', 'επιπλεον', 'επισημα', 'επισης', 'επομενο', 'επομενος', 'επομενως', 'επισης', 'επομενο', 'εργασια', 'ερωτησεις', 'εσεις', 'εσενα', 'εσυ', 'ευχαριστω', 'ευρω', 'εφοσον', 'ημερα', 'ημερες', 'ημερας', 'ηλικια', 'ηλικιας', 'ηλικιας', 'ημερομηνια', 'ημερομηνιας', 'ημερων', 'ημιτελης', 'ηδη', 'ηθελα', 'ηθελαν', 'ηθελαν', 'ηθελε', 'ηθελες', 'ηθελες', 'ηθελον', 'ηταν', 'αδιακοπα', 'αι', 'ακομα', 'ακομη', 'ακριβως', 'αληθεια', 'αληθινα', 'αλλα', 'αλλαχου', 'αλλες', 'αλλη', 'αλλην', 'αλλης', 'αλλιως', 'αλλιωτικα', 'αλλο', 'αλλοι', 'αλλοιως', 'αλλοιωτικα', 'αλλον', 'αλλος', 'αλλοτε', 'αλλου', 'αλλους', 'αλλων', 'αμα', 'αμεσα', 'αμεσως', 'αν', 'ανα', 'αναμεσα', 'αναμεταξυ', 'ανευ', 'αντι', 'αντιπερα', 'αντις', 'ανω', 'ανωτερω', 'αξαφνα', 'απ', 'απεναντι', 'απο', 'αποψε', 'αρα', 'αραγε', 'αργα', 'αργοτερο', 'αριστερα', 'αρκετα', 'αρχικα', 'ας', 'αυριο', 'αυτα', 'αυτες', 'αυτη', 'αυτην', 'αυτης', 'αυτο', 'αυτοι', 'αυτον', 'αυτος', 'αυτου', 'αυτους', 'αυτων', 'αφοτου', 'αφου', 'βεβαια', 'βεβαιοτατα', 'γι', 'για', 'γρηγορα', 'γυρω', 'δα', 'δε', 'δεινα', 'δεν', 'δεξια', 'δηθεν', 'δηλαδη', 'δι', 'δια', 'διαρκως', 'δικα', 'δικο', 'δικοι', 'δικος', 'δικου', 'δικους', 'διολου', 'διπλα', 'διχως', 'εαν', 'εαυτο', 'εαυτον', 'εαυτου', 'εαυτους', 'εαυτων', 'εγκαιρα', 'εγκαιρως', 'εγω', 'εδω', 'ειδεμη', 'ειθε', 'ειμαι', 'ειμαστε', 'ειναι', 'εις', 'εισαι', 'εισαστε', 'ειστε', 'ειτε', 'ειχα', 'ειχαμε', 'ειχαν', 'ειχατε', 'ειχε', 'ειχες', 'εκαστα', 'εκαστες', 'εκαστη', 'εκαστην', 'εκαστης', 'εκαστο', 'εκαστοι', 'εκαστον', 'εκαστος', 'εκαστου', 'εκαστους', 'εκαστων', 'εκει', 'εκεινα', 'εκεινες', 'εκεινη', 'εκεινην', 'εκεινης', 'εκεινο', 'εκεινοι', 'εκεινον', 'εκεινος', 'εκεινου', 'εκεινους', 'εκεινων', 'εκτος', 'εμας', 'εμεις', 'εμενα', 'εμπρος', 'εν', 'ενα', 'εναν', 'ενας', 'ενος', 'εντελως', 'εντος', 'εντωμεταξυ', 'ενω', 'εξ', 'εξαφνα', 'εξης', 'εξισου', 'εξω', 'επανω', 'επειδη', 'επειτα', 'επι', 'επισης', 'επομενως', 'εσας', 'εσεις', 'εσενα', 'εστω', 'εσυ', 'ετερα', 'ετεραι', 'ετερας', 'ετερες', 'ετερη', 'ετερης', 'ετερο', 'ετεροι', 'ετερον', 'ετερος', 'ετερου', 'ετερους', 'ετερων', 'ετουτα', 'ετουτες', 'ετουτη', 'ετουτην', 'ετουτης', 'ετουτο', 'ετουτοι', 'ετουτον', 'ετουτος', 'ετουτου', 'ετουτους', 'ετουτων', 'ετσι', 'ευγε', 'ευθυς', 'ευτυχως', 'εφεξης', 'εχει', 'εχεις', 'εχετε', 'εχθες', 'εχομε', 'εχουμε', 'εχουν', 'εχτες', 'εχω', 'εως', 'η', 'ηδη', 'ημασταν', 'ημαστε', 'ημουν', 'ησασταν', 'ησαστε', 'ησουν', 'ηταν', 'ητανε', 'ητοι', 'ηττον', 'θα', 'ι', 'ιδια', 'ιδιαν', 'ιδιας', 'ιδιες', 'ιδιο', 'ιδιοι', 'ιδιον', 'ιδιος', 'ιδιου', 'ιδιους', 'ιδιων', 'ιδιως', 'ιι', 'ιιι', 'ισαμε', 'ισια', 'ισως', 'καθε', 'καθεμια', 'καθεμιας', 'καθενα', 'καθενας', 'καθενος', 'καθετι', 'καθολου', 'καθως', 'και', 'κακα', 'κακως', 'καλα', 'καλως', 'καμια', 'καμιαν', 'καμιας', 'καμποσα', 'καμποσες', 'καμποση', 'καμποσην', 'καμποσης', 'καμποσο', 'καμποσοι', 'καμποσον', 'καμποσος', 'καμποσου', 'καμποσους', 'καμποσων', 'κανεις', 'κανεν', 'κανενα', 'κανεναν', 'κανενας', 'κανενος', 'καποια', 'καποιαν', 'καποιας', 'καποιες', 'καποιο', 'καποιοι', 'καποιον', 'καποιος', 'καποιου', 'καποιους', 'καποιων', 'καποτε', 'καπου', 'καπως', 'κατ', 'κατα', 'κατι', 'κατιτι', 'κατοπιν', 'κατω', 'κιολας', 'κλπ', 'κοντα', 'κτλ', 'κυριως', 'λιγακι', 'λιγο', 'λιγωτερο', 'λογω', 'λοιπα', 'λοιπον', 'μα', 'μαζι', 'μακαρι', 'μακρυα', 'μαλιστα', 'μαλλον', 'μας', 'με', 'μεθαυριο', 'μειον', 'μελει', 'μελλεται', 'μεμιας', 'μεν', 'μερικα', 'μερικες', 'μερικοι', 'μερικους', 'μερικων', 'μεσα', 'μετ', 'μετα', 'μεταξυ', 'μεχρι', 'μη', 'μηδε', 'μην', 'μηπως', 'μητε', 'μια', 'μιαν', 'μιας', 'μολις', 'μολονοτι', 'μοναχα', 'μονες', 'μονη', 'μονην', 'μονης', 'μονο', 'μονοι', 'μονομιας', 'μονος', 'μονου', 'μονους', 'μονων', 'μου', 'μπορει', 'μπορουν', 'μπραβο', 'μπρος', 'να', 'ναι', 'νωρις', 'ξανα', 'ξαφνικα', 'ο', 'οι', 'ολα', 'ολες', 'ολη', 'ολην', 'ολης', 'ολο', 'ολογυρα', 'ολοι', 'ολον', 'ολονεν', 'ολος', 'ολοτελα', 'ολου', 'ολους', 'ολων', 'ολως', 'ολωσδιολου', 'ομως', 'οποια', 'οποιαδηποτε', 'οποιαν', 'οποιανδηποτε', 'οποιας', 'οποιασδηποτε', 'οποιδηποτε', 'οποιες', 'οποιεσδηποτε', 'οποιο', 'οποιοδηποτε', 'οποιοι', 'οποιον', 'οποιονδηποτε', 'οποιος', 'οποιοσδηποτε', 'οποιου', 'οποιουδηποτε', 'οποιους', 'οποιουσδηποτε', 'οποιων', 'οποιωνδηποτε', 'οποτε', 'οποτεδηποτε', 'οπου', 'οπουδηποτε', 'οπως', 'ορισμενα', 'ορισμενες', 'ορισμενων', 'ορισμενως', 'οσα', 'οσαδηποτε', 'οσες', 'οσεσδηποτε', 'οση', 'οσηδηποτε', 'οσην', 'οσηνδηποτε', 'οσης', 'οσησδηποτε', 'οσο', 'οσοδηποτε', 'οσοι', 'οσοιδηποτε', 'οσον', 'οσονδηποτε', 'οσος', 'οσοσδηποτε', 'οσου', 'οσουδηποτε', 'οσους', 'οσουσδηποτε', 'οσων', 'οσωνδηποτε', 'οταν', 'οτι', 'οτιδηποτε', 'οτου', 'ου', 'ουδε', 'ουτε', 'οχι', 'παλι', 'παντοτε', 'παντου', 'παντως', 'παρα', 'περα', 'περι', 'περιπου', 'περισσοτερο', 'περσι', 'περυσι', 'πια', 'πιθανον', 'πιο', 'πισω', 'πλαι', 'πλεον', 'πλην', 'ποια', 'ποιαν', 'ποιας', 'ποιες', 'ποιο', 'ποιοι', 'ποιον', 'ποιος', 'ποιου', 'ποιους', 'ποιων', 'πολυ', 'ποσες', 'ποση', 'ποσην', 'ποσης', 'ποσοι', 'ποσος', 'ποσους', 'ποτε', 'που', 'πουθε', 'πουθενα', 'πρεπει', 'πριν', 'προ', 'προκειμενου', 'προκειται', 'προπερσι', 'προς', 'προτου', 'προχθες', 'προχτες', 'πρωτυτερα', 'πως', 'σαν', 'σας', 'σε', 'σεις', 'σημερα', 'σιγα', 'σου', 'στα', 'στη', 'στην', 'στης', 'στις', 'στο', 'στον', 'στου', 'στους', 'στων', 'συγχρονως', 'συν', 'συναμα', 'συνεπως', 'συνηθως', 'συχνα', 'συχνας', 'συχνες', 'συχνη', 'συχνην', 'συχνης', 'συχνο', 'συχνοι', 'συχνον', 'συχνος', 'συχνου', 'συχνου', 'συχνους', 'συχνων', 'συχνως', 'σχεδον', 'σωστα', 'τα', 'ταδε', 'ταυτα', 'ταυτες', 'ταυτη', 'ταυτην', 'ταυτης', 'ταυτο', 'ταυτον', 'ταυτος', 'ταυτου', 'ταυτων', 'ταχα', 'ταχατε', 'τελικα', 'τελικως', 'τες', 'τετοια', 'τετοιαν', 'τετοιας', 'τετοιες', 'τετοιο', 'τετοιοι', 'τετοιον', 'τετοιος', 'τετοιου', 'τετοιους', 'τετοιων', 'τη', 'την', 'της', 'τι', 'τιποτα', 'τιποτε', 'τις', 'το', 'τοι', 'τον', 'τος', 'τοσα', 'τοσες', 'τοση', 'τοσην', 'τοσης', 'τοσο', 'τοσοι', 'τοσον', 'τοσος', 'τοσου', 'τοσους', 'τοσων', 'τοτε', 'του', 'τουλαχιστο', 'τουλαχιστον', 'τους', 'τουτα', 'τουτες', 'τουτη', 'τουτην', 'τουτης', 'τουτο', 'τουτοι', 'τουτοις', 'τουτον', 'τουτος', 'τουτου', 'τουτους', 'τουτων', 'τυχον', 'των', 'τωρα', 'υπ', 'υπερ', 'υπο', 'υποψη', 'υποψιν', 'υστερα', 'φετος', 'χαμηλα', 'χθες', 'χτες', 'χωρις', 'χωριστα', 'ψηλα', 'ω', 'ωραια', 'ως', 'ωσαν', 'ωσοτου', 'ωσπου', 'ωστε', 'ωστοσο', 'ωχ', \n#           'ο', 'η', 'κ',  'εκλογες', 'δεν','γιατι', 'νεα','κανει','χρονια', 'ελλαδα', 'λεει','λεπω','λεμε','ειπα','ειπες','εβαλα','αδιακοπα','αι','ακομα','ακομη','ακριβως','αληθεια','αληθινα','αλλα','αλλαχου','αλλες','αλλη','αλλην','αλλης','αλλιως','αλλιωτικα','αλλο','αλλοι','αλλοιως','αλλοιωτικα','αλλον','αλλος','αλλοτε','αλλου','αλλους','αλλων','αμα','αμεσα','αμεσως','αν','ανα','αναμεσα','αναμεταξυ','ανευ','αντι','αντιπερα','αντις','ανω','ανωτερω','αξαφνα','απ','απεναντι','απο','αποψε','αρα','αραγε','αργα','αργοτερο','αριστερα','αρκετα','αρχικα','ας','αυριο','αυτα','αυτες','αυτη','αυτην','αυτης','αυτο','αυτοι','αυτον','αυτος','αυτου','αυτους','αυτων','αφοτου','αφου','βεβαια','βεβαιοτατα','γι','για','γρηγορα','γυρω','δα','δε','δεινα','δεν','δεξια','δηθεν','δηλαδη','δι','δια','διαρκως','δικα','δικο','δικοι','δικος','δικου','δικους','διολου','διπλα','διχως','εαν','εαυτο','εαυτον','εαυτου','εαυτους','εαυτων','εγκαιρα','εγκαιρως','εγω','εδω','ειδεμη','ειθε','ειμαι','ειμαστε','ειναι','εις','εισαι','εισαστε','ειστε','ειτε','ειχα','ειχαμε','ειχαν','ειχατε','ειχε','ειχες','εκαστα','εκαστες','εκαστη','εκαστην','εκαστης','εκαστο','εκαστοι','εκαστον','εκαστος','εκαστου','εκαστους','εκαστων','εκει','εκεινα','εκεινες','εκεινη','εκεινην','εκεινης','εκεινο','εκεινοι','εκεινον','εκεινος','εκεινου','εκεινους','εκεινων','εκτος','εμας','εμεις','εμενα','εμπρος','εν','ενα','εναν','ενας','ενος','εντελως','εντος','εντωμεταξυ','ενω','εξ','εξαφνα','εξης','εξισου','εξω','επανω','επειδη','επειτα','επι','επισης','επομενως','εσας','εσεις','εσενα','εστω','εσυ','ετερα','ετεραι','ετερας','ετερες','ετερη','ετερης','ετερο','ετεροι','ετερον','ετερος','ετερου','ετερους','ετερων','ετουτα','ετουτες','ετουτη','ετουτην','ετουτης','ετουτο','ετουτοι','ετουτον','ετουτος','ετουτου','ετουτους','ετουτων','ετσι','ευγε','ευθυς','ευτυχως','εφεξης','εχει','εχεις','εχετε','εχθες','εχομε','εχουμε','εχουν','εχτες','εχω','εως','η','ηδη','ημασταν','ημαστε','ημουν','ησασταν','ησαστε','ησουν','ηταν','ητανε','ητοι','ηττον','θα','ι','ιδια','ιδιαν','ιδιας','ιδιες','ιδιο','ιδιοι','ιδιον','ιδιος','ιδιου','ιδιους','ιδιων','ιδιως','ιι','ιιι','ισαμε','ισια','ισως','καθε','καθεμια','καθεμιας','καθενα','καθενας','καθενος','καθετι','καθολου','καθως','και','κακα','κακως','καλα','καλως','καμια','καμιαν','καμιας','καμποσα','καμποσες','καμποση','καμποσην','καμποσης','καμποσο','καμποσοι','καμποσον','καμποσος','καμποσου','καμποσους','καμποσων','κανεις','κανεν','κανενα','κανεναν','κανενας','κανενος','καποια','καποιαν','καποιας','καποιες','καποιο','καποιοι','καποιον','καποιος','καποιου','καποιους','καποιων','καποτε','καπου','καπως','κατ','κατα','κατι','κατιτι','κατοπιν','κατω','κιολας','κλπ','κοντα','κτλ','κυριως','λιγακι','λιγο','λιγωτερο','λογω','λοιπα','λοιπον','μα','μαζι','μακαρι','μακρυα','μαλιστα','μαλλον','μας','με','μεθαυριο','μειον','μελει','μελλεται','μεμιας','μεν','μερικα','μερικες','μερικοι','μερικους','μερικων','μεσα','μετ','μετα','μεταξυ','μεχρι','μη','μηδε','μην','μηπως','μητε','μια','μιαν','μιας','μολις','μολονοτι','μοναχα','μονες','μονη','μονην','μονης','μονο','μονοι','μονομιας','μονος','μονου','μονους','μονων','μου','μπορει','μπορουν','μπραβο','μπρος','να','ναι','νωρις','ξανα','ξαφνικα','ο','οι','ολα','ολες','ολη','ολην','ολης','ολο','ολογυρα','ολοι','ολον','ολονεν','ολος','ολοτελα','ολου','ολους','ολων','ολως','ολωςδιολου','ομως','οποια','οποιαδηποτε','οποιαν','οποιανδηποτε','οποιας','οποιαςδηποτε','οποιδηποτε','οποιες','οποιεςδηποτε','οποιο','οποιοδηποτε','οποιοι','οποιον','οποιονδηποτε','οποιος','οποιοςδηποτε','οποιου','οποιουδηποτε','οποιους','οποιουςδηποτε','οποιων','οποιωνδηποτε','οποτε','οποτεδηποτε','οπου','οπουδηποτε','οπως','ορισμενα','ορισμενες','ορισμενων','ορισμενως','οσα','οσαδηποτε','οσες','οσεςδηποτε','οση','οσηδηποτε','οσην','οσηνδηποτε','οσης','οσηςδηποτε','οσο','οσοδηποτε','οσοι','οσοιδηποτε','οσον','οσονδηποτε','οσος','οσοςδηποτε','οσου','οσουδηποτε','οσους','οσουςδηποτε','οσων','οσωνδηποτε','οταν','οτι','οτιδηποτε','οτου','ου','ουδε','ουτε','οχι','παλι','παντοτε','παντου','παντως','παρα','περα','περι','περιπου','περισσοτερο','περσι','περυσι','πια','πιθανον','πιο','πισω','πλαι','πλεον','πλην','ποια','ποιαν','ποιας','ποιες','ποιο','ποιοι','ποιον','ποιος','ποιου','ποιους','ποιων','πολυ','ποσες','ποση','ποσην','ποσης','ποσοι','ποσος','ποσους','ποτε','που','πουθε','πουθενα','πρεπει','πριν','προ','προκειμενου','προκειται','προπερσι','προς','προτου','προχθες','προχτες','πρωτυτερα','πως','σαν','σας','σε','σεις','σημερα','σιγα','σου','στα','στη','στην','στης','στις','στο','στον','στου','στους','στων','συγχρονως','συν','συναμα','συνεπως','συνηθως','συχνα','συχνας','συχνες','συχνη','συχνην','συχνης','συχνο','συχνοι','συχνον','συχνος','συχνου','συχνου','συχνους','συχνων','συχνως','σχεδον','σωστα','τα','ταδε','ταυτα','ταυτες','ταυτη','ταυτην','ταυτης','ταυτο,ταυτον','ταυτος','ταυτου','ταυτων','ταχα','ταχατε','τελικα','τελικως','τες','τετοια','τετοιαν','τετοιας','τετοιες','τετοιο','τετοιοι','τετοιον','τετοιος','τετοιου','τετοιους','τετοιων','τη','την','της','τι','τιποτα','τιποτε','τις','το','τοι','τον','τος','τοσα','τοσες','τοση','τοσην','τοσης','τοσο','τοσοι','τοσον','τοσος','τοσου','τοσους','τοσων','τοτε','του','τουλαχιστο','τουλαχιστον','τους','τουτα','τουτες','τουτη','τουτην','τουτης','τουτο','τουτοι','τουτοις','τουτον','τουτος','τουτου','τουτους','τουτων','τυχον','των','τωρα','υπ','υπερ','υπο','υποψη','υποψιν','υστερα','φετος','χαμηλα','χθες','χτες','χωρις','χωριστα','ψηλα','ω','ωραια','ως','ωσαν','ωσοτου','ωσπου','ωστε','ωστοσο','ωχ','ο','η','το','τα','τη','δηλαδη','μεχρι','γιατι','εχω','στους','μια','ένας','μία','κάποιος','κάποια','κάποιο','κάποιοι','αυτος','αυτη','αυτο','αυτοι','αυτες','αυτα','στο','στη','στα','για','με','απο','προς','ειναι','εχει','εχουν','θα','δεν','πανω','κατω','μεσα','εξω','κατω','ως','πανω','κατω','πιο','εδω','εκει','πολυ','λιγο','τωρα','ακομα','ομως','επισης','παντα','ακομη','πιθανως','μονο','οχι','ναι','ευχαριστως','γενικα','ολοι','ολες','ολα','ποιος','ποια','ποιο','ποιοι','ποιες','τιποτα','κανεις','καμια','κανενα','κανενες','αυτος','αυτη','αυτο','αυτοι','αυτες','αυτα','απο','σε','υπο','μετα','πριν','επειτα','αντι','εναν','μιαν','κανεναν','καμιαν','κανενα','καμια','μιαν','ενα','οποιος','οποια','οποιο','οποιοι','οποιες','οποιαν','οποιον','ολος','ολη','ολα','ολους','ολες','ολων','καθενας','καθεμια','καθενα','καθενες','ακομα','ενω','επομενως','συνεπως','επιπλεον','παρολα αυτα','παρ ολα αυτα','επισης','και','αλλα','αλλα και','αν','εαν','αν και','αντι','αντι να','αντι το','αντι τα','αντι του','αντι τη','αντι των','αντι στο','αντι στη','αντι στα','αντι στου','αντι στην','αντι στις','αντι στον','μεσω','τους','μας','ηταν','εκ','φορα','πρωτη','ειχα','εμεις','εσεις','ηδη','απ','εγινε','ειχε','αλλα','ουτε','ενας','εσας','αυτοι','αυτο','νεα','οντως','θελετε','κανει','σ','μας','πρεπε','ε','μαλιστα','τους','ηθελε','παω','εβαλε','λεει','γ','ν','θες','ερχεται','διαρκεια','θελουν','ασε','χ','λες','ξερω','α','δω','ειδε','μπηκε','βαλει','μερες','εφοσον','ενα','δυο','τρια','γινει','εργο','μιλαω','μιλησε','ποσα','ωρες','πρωινες','πρωτα','θελει','βαζω','εβαζε','εναντι','μπορεις','βρισκει','δει','μπορω','γινε','κανουν']\n\n# nowords=[]\ngreek_stopwords = stopwords.words('greek')\nnowords=greek_stopwords\n# \n# text editor gia kefalaia kai tonoys\ndef TextProccess(text):\n    text =text.strip()\n    return text\n\ndef PreProccessText(text):\n    oldtext=nltk.word_tokenize(text)\n    newtext=[]\n    for t in oldtext:\n        text=t.lower()\n        text=text.translate(str.maketrans('άίέύόώή' , 'αιευοωη'))\n        if text not in nowords:\n            newtext.append(TextProccess(text))\n    return newtext\n\n# take files\ndf = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/train_set.csv\", index_col=False)\ntest_df = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/test_set.csv\", index_col=False)\nval_df = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/valid_set.csv\", index_col=False)\n\n#  metatropi bgazeis @,# kena ,links ktl ktl\ntest_df['Text']=test_df['Text'].apply(lambda r:re.sub(r'@(\\w+)', '', r))\ntest_df['Text']=test_df['Text'].apply(lambda r:re.sub(r'#(\\w+)', '', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]', '', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'http\\S+', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[0-9]+', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'_',' ',r)) \ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r)) \ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r)) \n# test_df['Combined'] = test_df['party'] + test_df['sentiment']\n\nval_df['Text']=val_df['Text'].apply(lambda r:re.sub(r'@(\\w+)', '', r))\nval_df['Text']=val_df['Text'].apply(lambda r:re.sub(r'#(\\w+)', '', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]', '', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'http\\S+', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[0-9]+', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'_',' ',r)) \nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r)) \nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r)) \n# val_df['Combined'] = val_df['party'] + val_df['sentiment']\n\n# df['Combined'] = df['party'] + df['sentiment']\ndf['Text']=df['Text'].apply(lambda r:re.sub(r'@(\\w+)', '', r))\ndf['Text']=df['Text'].apply(lambda r:re.sub(r'#(\\w+)', '', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]', '', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'http\\S+', ' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[0-9]+', ' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'_',' ',r)) \ndf['Text'] = df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r)) \n# metatrepis sentiment se numbers kai to idio gia to party\ndf['sentiment']=df.Sentiment.map({\n    'POSITIVE':2,\n    'NEUTRAL':1,\n    'NEGATIVE':0  \n})\n# 01 02 03 \n# 04 05 06\n# 07 08 09\n# 10 11 12\n# 13 14 15\n# 16 17 18\n# arxika to ekana 0,1,2,3,4,5\ndf['party']=df.Party.map({\n    'SYRIZA':1,\n    'ND':4,\n    'KKE':7,\n    'PASOK':10,\n    'DIEM':13,\n    'ELL_LYSI':16        \n})\ntest_df['party']=test_df.Party.map({\n    'SYRIZA':1,\n    'ND':4,\n    'KKE':7,\n    'PASOK':10,\n    'DIEM':13,\n    'ELL_LYSI':16        \n})\nval_df['party']=val_df.Party.map({\n    'SYRIZA':1,\n    'ND':4,\n    'KKE':7,\n    'PASOK':10,\n    'DIEM':13,\n    'ELL_LYSI':16        \n})\nval_df['sentiment']=val_df.Sentiment.map({\n    'POSITIVE':2,\n    'NEUTRAL':1,\n    'NEGATIVE':0  \n})\n\n\n# perneis 90% ton test\nText_train,Text_val,Sentiment_train,Sentiment_val= train_test_split(df['Text'] ,df['sentiment'],random_state=1000 , test_size=0.1,stratify=df.sentiment,shuffle=True)\n# Text_train=df['Text'] \nText_val=val_df['Text']\n# Sentiment_train=df['sentiment'] \nSentiment_val=val_df['sentiment'] \nText_sub=test_df['Text']\n# metatrepis ta text\nTweets=[]\nfor text in Text_train:\n    Tweets.append(\" \".join(PreProccessText(text)))\n\nTweets_test=[]\nfor text in Text_val:\n    Tweets_test.append(\" \".join(PreProccessText(text)))   \n\nTweets_sub=[]\nfor text in Text_sub:\n    Tweets_sub.append(\" \".join(PreProccessText(text)))   \n    \n\n\n\n# max_df=0.3,smooth_idf=True,use_idf=True\n# create vectorizer\nvectorizer = TfidfVectorizer(max_df=0.3,smooth_idf=True,use_idf=True)\nTweets_train=vectorizer.fit_transform(Tweets)\nTweets_val=vectorizer.transform(Tweets_test)\nTweets_to_sub=vectorizer.transform(Tweets_sub)\n# logicregression and prediction\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(Tweets_train,np.ravel(Sentiment_train))\n# predict\ny1=logreg.predict(Tweets_val)\npredict_sentiment_sub=logreg.predict(Tweets_to_sub)\n# \n# create submission file\npred=[]\nfor pe in predict_sentiment_sub:\n    if pe==1:\n        pred.append('NEUTRAL')\n    if pe==2:\n        pred.append('POSITIVE')     \n    if pe==0:\n        pred.append('NEGATIVE') \n\ndata = pd.Series(pred)\nSUB=test_df[['New_ID']]\nSUB.rename(columns = {'New_ID':'Id'}, inplace = True)\nSUB[\"Predicted\"]=data\nSUB.to_csv(\"submission.csv\",index=None)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:48:40.885639Z","iopub.execute_input":"2023-11-12T16:48:40.886033Z","iopub.status.idle":"2023-11-12T16:49:17.685757Z","shell.execute_reply.started":"2023-11-12T16:48:40.885995Z","shell.execute_reply":"2023-11-12T16:49:17.682952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print the word count\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(Tweets)\nword_counts = X.sum(axis=0)\nfeature_names = vectorizer.get_feature_names_out()\nword_count_df = pd.DataFrame(data=word_counts, columns=feature_names)\nword_count_df = word_count_df.T\nword_count_df = word_count_df.sort_values(by=0, ascending=False)\n\ntop_n = 20  \nplt.figure(figsize=(10, 6))\nword_count_df.head(top_n).plot(kind='bar', legend=False)\nplt.title(f'Top {top_n} Words in Tweets Text')\nplt.xlabel('Word')\nplt.ylabel('Count')\nplt.show()\n\n\n# print the f1_score\nprint(classification_report(Sentiment_val,y1))\n# \n\n# print learning curve\nplot_learning_curves(Tweets_train,Sentiment_train,Tweets_val,Sentiment_val,logreg)\n# \n\n# print confusion matrix\nconfusion_matrix = metrics.confusion_matrix(y1, Sentiment_val)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['POSITIVE','NEUTRAL', 'NEGATIVE'], yticklabels=['POSITIVE','NEUTRAL', 'NEGATIVE'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\nprobas = logreg.predict_proba(Tweets_val)[:, 1]\n\n# print roc_curve\ndef custom_roc_curve(y_true, y_scores, plot=True):\n    thresholds = np.linspace(0, 1, 100)\n    tpr_values = []\n    fpr_values = []\n\n    for threshold in thresholds:\n        y_pred = (y_scores >= threshold).astype(int)\n        true_positive = np.sum((y_pred == 1) & (y_true == 1))\n        false_positive = np.sum((y_pred == 1) & (y_true == 0))\n        true_negative = np.sum((y_pred == 0) & (y_true == 0))\n        false_negative = np.sum((y_pred == 0) & (y_true == 1))\n\n        tpr = true_positive / (true_positive + false_negative)\n        fpr = false_positive / (false_positive + true_negative)\n\n        tpr_values.append(tpr)\n        fpr_values.append(fpr)\n\n    if plot:\n        plt.figure(figsize=(8, 8))\n        plt.plot(fpr_values, tpr_values, color='darkorange', lw=2, label='ROC curve')\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic (ROC) Curve')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    return fpr_values, tpr_values\n\n# call the print roc_curve\nfpr_custom, tpr_custom = custom_roc_curve(Sentiment_val, probas)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:49:17.688382Z","iopub.execute_input":"2023-11-12T16:49:17.689387Z","iopub.status.idle":"2023-11-12T16:50:49.749916Z","shell.execute_reply.started":"2023-11-12T16:49:17.689340Z","shell.execute_reply":"2023-11-12T16:50:49.748643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download el_core_news_lg","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:50:49.752631Z","iopub.execute_input":"2023-11-12T16:50:49.753090Z","iopub.status.idle":"2023-11-12T16:51:23.969976Z","shell.execute_reply.started":"2023-11-12T16:50:49.753058Z","shell.execute_reply":"2023-11-12T16:51:23.968292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gia na leitoyrgisei prepei na ginei prota download to el_core_news_lg\n# aytos einai o deyteros kodikas me thn xrisi toy spacy epeidi einai arketa diaforetikos ton kratisa gia anagnosi\n\n# stop words\ngreek_stopwords = stopwords.words('greek')\nnowords=greek_stopwords\n# read file\ndf = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/train_set.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/test_set.csv\")\nval_df = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/valid_set.csv\")\n\n#  metatropi bgazeis @,# kena ,links ktl ktl\ntest_df['Text']=test_df['Text'].apply(lambda r:re.sub(r'@(\\w+)', ' ', r))\ntest_df['Text']=test_df['Text'].apply(lambda r:re.sub(r'#(\\w+)', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'http\\S+', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[0-9]+', ' ', r))\ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'_',' ',r)) \ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r)) \ntest_df['Text'] =test_df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r)) \n\nval_df['Text']=val_df['Text'].apply(lambda r:re.sub(r'@(\\w+)', ' '  ,r))\nval_df['Text']=val_df['Text'].apply(lambda r:re.sub(r'#(\\w+)', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'http\\S+', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[0-9]+', ' ', r))\nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'_',' ',r)) \nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r)) \nval_df['Text'] =val_df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r)) \n\ndf['Text']=df['Text'].apply(lambda r:re.sub(r'@(\\w+)',' ', r))\ndf['Text']=df['Text'].apply(lambda r:re.sub(r'#(\\w+)',' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[^\\w\\s]',' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'http\\S+',' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[0-9]+',' ', r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'_','',r)) \ndf['Text'] = df['Text'].apply(lambda r:re.sub(\"\\s\\s+\", \" \", r))\ndf['Text'] = df['Text'].apply(lambda r:re.sub(r'[a-zA-Z]+',' ',r))\n\n# sentiment se noymera\ndf['sentiment']=df.Sentiment.map({\n    'POSITIVE':2,\n    'NEUTRAL':1,\n    'NEGATIVE':0  \n})\nval_df['sentiment']=val_df.Sentiment.map({\n    'POSITIVE':2,\n    'NEUTRAL':1,\n    'NEGATIVE':0  \n})\n\n# me thn spacy ta kano lemetaization kai bgazo alla stoixeia\nT=df['Text']\ntell=[]\nfor token in T:\n    oldtext=nltk.word_tokenize(token)\n    tell.append(' '.join(oldtext))\n\n\nTweets=[]\nnlp = spacy.load('el_core_news_lg')\nfor a in tell:\n    doc = nlp(a)\n    Tweets2=[]\n    for token in doc:\n        if token.like_num==False  and token.is_stop==False and (token.lemma_ not in nowords):\n            text=token.lemma_.translate(str.maketrans('άίέύόώή' , 'αιευοωη'))\n            text=text.lower()\n            Tweets2.append(''.join(text))\n    Tweets.append(' '.join(Tweets2))\n    \n\n\nT=val_df['Text']\ntell=[]\nfor token in T:\n    oldtext=nltk.word_tokenize(token)\n    tell.append(' '.join(oldtext))\n\nTweets_test=[]\nfor a in tell:\n    doc = nlp(a)\n    Tweets2=[]\n    for token in doc:\n        if token.like_num==False  and token.is_stop==False and (token.lemma_ not in nowords) :\n            text=token.lemma_.translate(str.maketrans('άίέύόώή' , 'αιευοωη'))\n            text=text.lower()\n            Tweets2.append(''.join(text))\n    Tweets_test.append(' '.join(Tweets2))\n\n# perno sentiment arithmoys\nSentiment_train=df['sentiment']\nSentiment_val=val_df['sentiment'] \n\n# vectorizer\n# max_df=0.3,smooth_idf=True,use_idf=True\nvectorizer = TfidfVectorizer()\nTweets_t=vectorizer.fit_transform(Tweets)\nTweets_try=vectorizer.transform(Tweets_test)\n# logisticregression and predict\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(Tweets_t,np.ravel(Sentiment_train))\ny1=logreg.predict(Tweets_try)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:51:23.972544Z","iopub.execute_input":"2023-11-12T16:51:23.975358Z","iopub.status.idle":"2023-11-12T16:59:50.303368Z","shell.execute_reply.started":"2023-11-12T16:51:23.975307Z","shell.execute_reply":"2023-11-12T16:59:50.301331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print the word count\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(Tweets)\nword_counts = X.sum(axis=0)\nfeature_names = vectorizer.get_feature_names_out()\nword_count_df = pd.DataFrame(data=word_counts, columns=feature_names)\nword_count_df = word_count_df.T\nword_count_df = word_count_df.sort_values(by=0, ascending=False)\n\ntop_n = 20  \nplt.figure(figsize=(10, 6))\nword_count_df.head(top_n).plot(kind='bar', legend=False)\nplt.title(f'Top {top_n} Words in Tweets Text')\nplt.xlabel('Word')\nplt.ylabel('Count')\nplt.show()\n\n\n\n# print the f1_score\nprint(classification_report(Sentiment_val,y1))\n# \n\n# print learning curve\nplot_learning_curves(Tweets_t,Sentiment_train, Tweets_try,Sentiment_val,logreg)\n# \n\nprobas = logreg.predict_proba(Tweets_try)[:, 1]\n\n# print confusion matrix\nconfusion_matrix = metrics.confusion_matrix(y1, Sentiment_val)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['POSITIVE','NEUTRAL', 'NEGATIVE'], yticklabels=['POSITIVE','NEUTRAL', 'NEGATIVE'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n\n# print roc_curve\ndef custom_roc_curve(y_true, y_scores, plot=True):\n    thresholds = np.linspace(0, 1, 100)\n    tpr_values = []\n    fpr_values = []\n\n    for threshold in thresholds:\n        y_pred = (y_scores >= threshold).astype(int)\n        true_positive = np.sum((y_pred == 1) & (y_true == 1))\n        false_positive = np.sum((y_pred == 1) & (y_true == 0))\n        true_negative = np.sum((y_pred == 0) & (y_true == 0))\n        false_negative = np.sum((y_pred == 0) & (y_true == 1))\n\n        tpr = true_positive / (true_positive + false_negative)\n        fpr = false_positive / (false_positive + true_negative)\n\n        tpr_values.append(tpr)\n        fpr_values.append(fpr)\n\n    if plot:\n        plt.figure(figsize=(8, 8))\n        plt.plot(fpr_values, tpr_values, color='darkorange', lw=2, label='ROC curve')\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic (ROC) Curve')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    return fpr_values, tpr_values\n\n# call the print roc_curve\nfpr_custom, tpr_custom = custom_roc_curve(Sentiment_val, probas)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:59:50.307001Z","iopub.execute_input":"2023-11-12T16:59:50.309626Z","iopub.status.idle":"2023-11-12T17:01:41.967786Z","shell.execute_reply.started":"2023-11-12T16:59:50.309560Z","shell.execute_reply":"2023-11-12T17:01:41.966321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# na xrisimopoiiso ayta sto mellon na mhn xano xrono me to xeri / GridSearchCV or Optuna/ for next project this comment for me\ndf=pd.read_csv(\"/kaggle/working/submission.csv\")\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T17:01:41.971403Z","iopub.execute_input":"2023-11-12T17:01:41.971819Z","iopub.status.idle":"2023-11-12T17:01:42.003713Z","shell.execute_reply.started":"2023-11-12T17:01:41.971776Z","shell.execute_reply":"2023-11-12T17:01:42.002469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}